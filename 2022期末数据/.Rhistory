})
n = column
with(data,{
n = column
print(n)
})
# 主成分分析
rm(list = ls())
data = read.csv("/Users/vielyi/Desktop/project/2022期末数据/departements_cas.csv",header = T)
# 主成分分析
data_sub = data[,c(3:6)]
data1 = scale(data_sub)
data.pr = princomp(data1 ,cor = FALSE, scores = TRUE)
summary(data.pr,loadings=TRUE)
data.pr1 = prcomp(data1,center = TRUE, scale. = TRUE)
data.pr1
summary(data.pr1)
screeplot(data.pr,type = "lines") # 主成分（4个主成分权重）
pre = predict(data.pr)
pre
# 支持向量机
library(e1071)
fit = svm(formula = KÉDOUGOU ~ MBACKÉ + GUÉDIAWAYE,
data = data,
type = "C-classification",
kernel = "radial",
scale = TRUE,
gamma = 1,
cost = 1)
fit = svm(formula = KÉDOUGOU ~ MBACKÉ + GUÉDIAWAYE,
data = data,
type = "C-classification",
kernel = "radial",
scale = TRUE,
gamma = 0.2,
cost = 1)
summary(fit)
fit = svm(formula = KÉDOUGOU ~ MBACKÉ + GUÉDIAWAYE,
data = data,
type = "C-classification",
kernel = "radial",
scale = TRUE,
gamma = 0.2,
cost = 0.2)
summary(fit)
# 支持向量机
srt(data)
# 支持向量机
str(data)
data$KÉDOUGOU = as.factor(data$KÉDOUGOU)
library(e1071)
fit = svm(formula = KÉDOUGOU ~ MBACKÉ + GUÉDIAWAYE,
data = data,
type = "C-classification",
kernel = "radial",
scale = TRUE,
gamma = 0.2,
cost = 0.2)
summary(fit)
fit = svm(formula = KÉDOUGOU ~ MBACKÉ + GUÉDIAWAYE,
data = data,
type = "C-classification", #分类
kernel = "sigmodi", #选择核函数
scale = TRUE,
gamma = 0.2,
cost = 0.2)
fit = svm(formula = KÉDOUGOU ~ MBACKÉ + GUÉDIAWAYE,
data = data,
type = "C-classification", #分类
kernel = "sigmoid", #选择核函数
scale = TRUE,
gamma = 0.2,
cost = 0.2)
summary(fit)
fit = svm(formula = KÉDOUGOU ~ MBACKÉ + GUÉDIAWAYE,
data = data,
type = "C-classification", #分类
kernel = "sigmoid", #选择核函数
scale = TRUE,
gamma = 1,
cost = 0.2)
summary(fit)
## 自动调参
tuning = tune(svm,
formula = KÉDOUGOU ~ MBACKÉ + GUÉDIAWAYE,
data = data,
kernel = "sigmoid",
type = "C-classification",
ranges = list(
cost = c(0.001, 0.01, 0.1, 1),
gamma = seq(1:5)),
tunecontrol = tune.control(
sampling = "cross", # 选择标准，交叉验证
cross = 20),
probability = TRUE)
rm(list = ls())
data = read.csv("/Users/vielyi/Desktop/project/2022期末数据/departements_cas.csv",header = T)
# 主成分分析
data_sub = data[,c(3:6)]
data1 = scale(data_sub)
data.pr = princomp(data1 ,cor = FALSE, scores = TRUE)
summary(data.pr,loadings=TRUE)
data.pr1 = prcomp(data1,center = TRUE, scale. = TRUE)
data.pr1
summary(data.pr1)
screeplot(data.pr,type = "lines") # 主成分（4个主成分权重）
pre = predict(data.pr)
pre
# 支持向量机
library(e1071)
str(data) # 查看dataframe属性类型
data$KÉDOUGOU = as.factor(data$KÉDOUGOU)
fit = svm(formula = KÉDOUGOU ~ MBACKÉ + GUÉDIAWAYE,
data = data,
type = "C-classification", #分类
kernel = "sigmoid", #选择核函数
scale = TRUE,
gamma = 1,
cost = 0.2)
summary(fit)
## 自动调参
tuning = tune(svm,
formula = KÉDOUGOU ~ MBACKÉ + GUÉDIAWAYE,
data = data,
kernel = "sigmoid",
type = "C-classification",
ranges = list(
cost = c(0.001, 0.01, 0.1, 1),
gamma = seq(1:5)),
tunecontrol = tune.control(
sampling = "cross", # 选择标准，交叉验证k-folded
cross = 20),
probability = TRUE)
summary(tuning)
## 自动调参
tuning = tune(svm,
KÉDOUGOU ~ MBACKÉ + GUÉDIAWAYE,
data = data,
kernel = "sigmoid",
type = "C-classification",
ranges = list(
cost = c(0.001, 0.01, 0.1, 1),
gamma = seq(1:5)),
tunecontrol = tune.control(
sampling = "cross", # 选择标准，交叉验证k-folded
cross = 20),
probability = TRUE)
summary(tuning)
best = tuning$best.model # 获取调参得到的最优模型
tuning$best.parameters
summary(best)
data$MBACKÉ
data$GUÉDIAWAYE
predict(best, data.frame(x1 = c(300,400,500),x2 = c(100,150,200)))
data.frame(x1 = c(300,400,500),x2 = c(100,150,200))
predict(best, data.frame(MBACKÉ = c(300,400,500),GUÉDIAWAYE = c(100,150,200)))
predict(best, data.frame(MBACKÉ = c(300,400,500),GUÉDIAWAYE = c(100,150,200)),probability = TRUE)
plot(best, # 拟合得到的model
data, # 数据集
svSymbol = 1, # 支持向量数据点的类型, 1 三角形
dataSymbol = 2, # 非支持向量数据点的类型, 2 圆
symbolPalette = rainbow(2), # 数据点所属类的颜色板
color.palette = cm.colors) # 分类调色板
best
summary(best)
plot(fit, # 拟合得到的model
data, # 数据集
svSymbol = 1, # 支持向量数据点的类型, 1 三角形
dataSymbol = 2, # 非支持向量数据点的类型, 2 圆
symbolPalette = rainbow(2), # 数据点所属类的颜色板
color.palette = cm.colors) # 分类调色板
plot(best, # 拟合得到的model
data, # 数据集
formula = KÉDOUGOU ~ MBACKÉ + GUÉDIAWAYE,
svSymbol = 1, # 支持向量数据点的类型, 1 三角形
dataSymbol = 2, # 非支持向量数据点的类型, 2 圆
symbolPalette = rainbow(2), # 数据点所属类的颜色板
color.palette = cm.colors) # 分类调色板
rm(list = ls())
data = read.csv("/Users/vielyi/Desktop/project/2022期末数据/departements_cas.csv",header = T)
# 主成分分析
data_sub = data[,c(3:6)]
data1 = scale(data_sub)
data.pr = princomp(data1 ,cor = FALSE, scores = TRUE)
summary(data.pr,loadings=TRUE)
data.pr1 = prcomp(data1,center = TRUE, scale. = TRUE)
data.pr1
summary(data.pr1)
screeplot(data.pr,type = "lines") # 主成分（4个主成分权重）
pre = predict(data.pr)
pre
# 支持向量机
library(e1071)
str(data) # 查看dataframe属性类型
data$KÉDOUGOU = as.factor(data$KÉDOUGOU)
fit = svm(formula = KÉDOUGOU ~ MBACKÉ + GUÉDIAWAYE,
data = data,
type = "C-classification", #分类
kernel = "sigmoid", #选择核函数
scale = TRUE,
gamma = 1,
cost = 0.2)
summary(fit)
## 自动调参
tuning = tune(svm,
KÉDOUGOU ~ MBACKÉ + GUÉDIAWAYE,
data = data,
kernel = "sigmoid",
type = "C-classification",
ranges = list(
cost = c(0.001, 0.01, 0.1, 1),
gamma = seq(1:5)),
tunecontrol = tune.control(
sampling = "cross", # 选择标准，交叉验证k-folded
cross = 20),
probability = TRUE)
summary(tuning)
best = tuning$best.model # 获取调参得到的最优模型
tuning$best.parameters
rm(list = ls())
data = read.csv("/Users/vielyi/Desktop/project/2022期末数据/departements_cas.csv",header = T)
# 支持向量机
library(e1071)
str(data) # 查看dataframe属性类型
# data$KÉDOUGOU = as.factor(data$KÉDOUGOU)
fit = svm(formula = KÉDOUGOU ~ MBACKÉ + GUÉDIAWAYE,
data = data,
type = "C-classification", #分类
kernel = "sigmoid", #选择核函数
scale = TRUE,
gamma = 1,
cost = 0.2)
summary(fit)
## 自动调参
tuning = tune(svm,
KÉDOUGOU ~ MBACKÉ + GUÉDIAWAYE,
data = data,
kernel = "sigmoid",
type = "C-classification",
ranges = list(
cost = c(0.001, 0.01, 0.1, 1),
gamma = seq(1:5)),
tunecontrol = tune.control(
sampling = "cross", # 选择标准，交叉验证k-folded
cross = 20),
probability = TRUE)
data$KÉDOUGOU = as.factor(data$KÉDOUGOU)
## 自动调参
tuning = tune(svm,
KÉDOUGOU ~ MBACKÉ + GUÉDIAWAYE,
data = data,
kernel = "sigmoid",
type = "C-classification",
ranges = list(
cost = c(0.001, 0.01, 0.1, 1),
gamma = seq(1:5)),
tunecontrol = tune.control(
sampling = "cross", # 选择标准，交叉验证k-folded
cross = 20),
probability = TRUE)
summary(tuning)
best = tuning$best.model # 获取调参得到的最优模型
tuning$best.parameters
summary(best)
predict(best, data.frame(MBACKÉ = c(300,400,500),GUÉDIAWAYE = c(100,150,200)))
predict(best, data.frame(MBACKÉ = c(300,400,500),GUÉDIAWAYE = c(100,150,200)),probability = TRUE)
plot(best, # 拟合得到的model
data, # 数据集
formula = KÉDOUGOU ~ MBACKÉ + GUÉDIAWAYE,
svSymbol = 1, # 支持向量数据点的类型, 1 三角形
dataSymbol = 2, # 非支持向量数据点的类型, 2 圆
symbolPalette = rainbow(2), # 数据点所属类的颜色板
color.palette = cm.colors) # 分类调色板
data$KÉDOUGOU = as.integer(data$KÉDOUGOU)
plot(best, # 拟合得到的model
data, # 数据集
formula = KÉDOUGOU ~ MBACKÉ + GUÉDIAWAYE,
svSymbol = 1, # 支持向量数据点的类型, 1 三角形
dataSymbol = 2, # 非支持向量数据点的类型, 2 圆
symbolPalette = rainbow(2), # 数据点所属类的颜色板
color.palette = cm.colors) # 分类调色板
rm(list = ls())
data = read.csv("/Users/vielyi/Desktop/project/2022期末数据/departements_cas.csv",header = T)
# 主成分分析
data_sub = data[,c(3:6)]
data1 = scale(data_sub)
data.pr = princomp(data1 ,cor = FALSE, scores = TRUE)
summary(data.pr,loadings=TRUE)
data.pr1 = prcomp(data1,center = TRUE, scale. = TRUE)
data.pr1
summary(data.pr1)
screeplot(data.pr,type = "lines") # 主成分（4个主成分权重）
pre = predict(data.pr)
pre
# 支持向量机
library(e1071)
str(data) # 查看dataframe属性类型
data$KÉDOUGOU = as.factor(data$KÉDOUGOU)
fit = svm(formula = KÉDOUGOU ~ MBACKÉ + GUÉDIAWAYE,
data = data,
type = "C-classification", #分类
kernel = "sigmoid", #选择核函数
scale = TRUE,
gamma = 1,
cost = 0.2)
summary(fit)
## 自动调参
tuning = tune(svm,
KÉDOUGOU ~ MBACKÉ + GUÉDIAWAYE,
data = data,
kernel = "sigmoid",
type = "C-classification",
ranges = list(
cost = c(0.001, 0.01, 0.1, 1),
gamma = seq(1:5)),
tunecontrol = tune.control(
sampling = "cross", # 选择标准，交叉验证k-folded
cross = 20),
probability = TRUE)
summary(tuning)
best = tuning$best.model # 获取调参得到的最优模型
tuning$best.parameters
summary(best)
predict(best, data.frame(MBACKÉ = c(300,400,500),GUÉDIAWAYE = c(100,150,200)))
predict(best, data.frame(MBACKÉ = c(300,400,500),GUÉDIAWAYE = c(100,150,200)),probability = TRUE)
plot(best, # 拟合得到的model
data, # 数据集
formula = KÉDOUGOU ~ MBACKÉ + GUÉDIAWAYE,
svSymbol = 1, # 支持向量数据点的类型, 1 三角形
dataSymbol = 2, # 非支持向量数据点的类型, 2 圆
symbolPalette = rainbow(2), # 数据点所属类的颜色板
color.palette = cm.colors) # 分类调色板
data$KÉDOUGOU = as.numeric(data$KÉDOUGOU)
plot(best, # 拟合得到的model
data, # 数据集
formula = KÉDOUGOU ~ MBACKÉ + GUÉDIAWAYE,
svSymbol = 1, # 支持向量数据点的类型, 1 三角形
dataSymbol = 2, # 非支持向量数据点的类型, 2 圆
symbolPalette = rainbow(2), # 数据点所属类的颜色板
color.palette = cm.colors) # 分类调色板
plot(best, # 拟合得到的model
data, # 数据集
svSymbol = 1, # 支持向量数据点的类型, 1 三角形
dataSymbol = 2, # 非支持向量数据点的类型, 2 圆
symbolPalette = rainbow(2), # 数据点所属类的颜色板
color.palette = cm.colors) # 分类调色板
# 神经网络
library(neuralnet)
rm(list = ls())
data = read.csv("/Users/vielyi/Desktop/project/2022期末数据/departements_cas.csv",header = T)
# 主成分分析
data_sub = data[,c(3:6)]
data1 = scale(data_sub)
data.pr = princomp(data1 ,cor = FALSE, scores = TRUE)
summary(data.pr,loadings=TRUE)
data.pr1 = prcomp(data1,center = TRUE, scale. = TRUE)
data.pr1
summary(data.pr1)
screeplot(data.pr,type = "lines") # 主成分（4个主成分权重）
pre = predict(data.pr)
pre
# 支持向量机
library(e1071)
str(data) # 查看dataframe属性类型
data$KÉDOUGOU = as.factor(data$KÉDOUGOU)
fit = svm(formula = KÉDOUGOU ~ MBACKÉ + GUÉDIAWAYE,
data = data,
type = "C-classification", #分类
kernel = "sigmoid", #选择核函数
scale = TRUE,
gamma = 1,
cost = 0.2)
summary(fit)
## 自动调参
tuning = tune(svm,
KÉDOUGOU ~ MBACKÉ + GUÉDIAWAYE,
data = data,
kernel = "sigmoid",
type = "C-classification",
ranges = list(
cost = c(0.001, 0.01, 0.1, 1),
gamma = seq(1:5)),
tunecontrol = tune.control(
sampling = "cross", # 选择标准，交叉验证k-folded
cross = 20),
probability = TRUE)
summary(tuning)
best = tuning$best.model # 获取调参得到的最优模型
tuning$best.parameters
summary(best)
predict(best, data.frame(MBACKÉ = c(300,400,500),GUÉDIAWAYE = c(100,150,200)))
predict(best, data.frame(MBACKÉ = c(300,400,500),GUÉDIAWAYE = c(100,150,200)),probability = TRUE)
# 神经网络
library(neuralnet)
rm(list = ls())
data = read.csv("/Users/vielyi/Desktop/project/2022期末数据/NMDS_coordinates.csv",header = T)
str(data)
c(2,30:33)
rm(list = ls())
data = read.csv("/Users/vielyi/Desktop/project/2022期末数据/NMDS_coordinates.csv",header = T)
str(data)
data = data[,c(2,30:33)]
srt(data)
str(data)
normalize = function(x){
return((x-min(x))/(max(x)-min(x)))
}
concrete_norm = as.data.frame(lapply(data,normalize)) #lapply()将函数运用于每一列
data_norm = as.data.frame(lapply(data,normalize)) #lapply()将函数运用于每一列
summary(data_norm$strength)
summary(data_norm)
## 随机抽样分数据集为训练集和测试集
set.seed(1)
index = sample(nrow(data_norm),nrow(data_norm)*.7,replace=F)
train_set = data_norm[index,]
test_set = data_norm[-index,]
## 训练模型
model = neuralnet(NMDS1 ~ days + Vel + X_Vel + MidPt,
data = train_set)
model_results = compute(model,test_set[1:8])
model_results = compute(model,test_set[1:])
model_results = compute(model,test_set[1:4])
predicted_NMDS1 = model_results$net.result
cor(predicted_NMDS1,test_set$NMDS1)
plot(concrete_model)
plot(model)
train_sse = model$result.matrix[1]
predict_sse = sum(1/2*(predicted_NMDS1-test_set$NMDS1)^2)
c(variance = predict_sse/(ntest-8),bias=train_sse/(ntrain-8))
ntest = length(test_set)
ntest
ntest = length(test_set$NMDS1)
ntest = length(test_set$NMDS1)
ntrain = length(train_set$NMDS1)
train_sse = model$result.matrix[1]
predict_sse = sum(1/2*(predicted_NMDS1-test_set$NMDS1)^2)
c(variance = predict_sse/(ntest-5),bias = train_sse/(ntrain-5))
#######################
# 偏最小二乘 ##########
#######################
library(pls)
rm(list = ls())
data = read.csv("NMDS_coordinates.csv",header = T)
str(data)
data = data[,c(2,30:33)]
str(data)
setwd("/Users/vielyi/Desktop/课程/统计软件/project/2022期末数据")
rm(list = ls()) # 清除变量
data = read.csv("departements_cas.csv",header = T)
#######################
# 偏最小二乘 ##########
#######################
library(pls)
rm(list = ls())
data = read.csv("NMDS_coordinates.csv",header = T)
str(data)
data = data[,c(2,30:33)]
str(data)
normalize = function(x){
return((x-min(x))/(max(x)-min(x)))
}
data_norm = as.data.frame(lapply(data,normalize))
summary(data_norm)
## 随机抽样分数据集为训练集和测试集
set.seed(1)
index = sample(nrow(data_norm),nrow(data_norm)*.7,replace=F)
train_set = data_norm[index,]
test_set = data_norm[-index,]
##先进行线性回归
attach(train_set)
lr_model = lm(NMDS1 ~ days+Vel+X_Vel+MidPt)
pred_lr = predict(lr_model, newdata = test_set)
RMSE_lr = sqrt(mean((test_set$NMDS1-pred_lr)^2))
RMSE_lr
detach(train_set)
## 然后进行主成分回归
attach(train_set)
pcr_mode1 = pcr(NMDS1 ~ days+Vel+X_Vel+MidPt,scale=TRUE,validation="CV")
validationplot(pcr_mode1,val.type="RMSEP")
summary(pcr_mode1)
## 选用2个进行主成分
pcr_model2 = pcr(NMDS1 ~ days+Vel+X_Vel+MidPt,scale=TRUE,validation="CV",ncomp=2)
summary(pcr_model2)
coef(pcr_model2)
pred_pcr2 = predict(pcr_model2,newdata = test_set,ncomp = 2)
RMSE_pcr2 = sqrt(mean((test_set$NMDS1-pred_pcr2)^2))
RMSE_pcr2
detach(train_set)
## pls偏最小二乘
attach(train_set)
pls_model = plsr(NMDS1 ~ days+Vel+X_Vel+MidPt,validation="LOO",scale=T,jackknife=T)
summary(pls_model)
plot(RMSEP(pls_model))
## 2个成分
pls_model2 = plsr(NMDS1 ~ days+Vel+X_Vel+MidPt,ncomp=2,scale=T,validation="LOO")
summary(pls_model2)
loading.weights(pls_model2)
coef(pls_model2)
pred_plsr2 =predict(pls_model2,newdata = test_set,ncomp=2)
RMSE_plsr2 = sqrt(mean((test_set$NMDS1-pred_plsr2)^2))
RMSE_plsr2
## 3个成分
pls_model3 = plsr(NMDS1 ~ days+Vel+X_Vel+MidPt,ncomp=3,scale=T,validation="LOO")
summary(pls_model3)
loading.weights(pls_model3)
coef(pls_model3)
pred_plsr3 = predict(pls_model3,newdata = test_set,ncomp = 3)
RMSE_plsr3 = sqrt(mean((test_set$NMDS1-pred_plsr3)^2))
RMSE_plsr3
detach(train_set)
coef(pls_model2)
loading.weights(pls_model2)
