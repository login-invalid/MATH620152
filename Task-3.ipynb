{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorh 实例\n",
    "因为本实例采用不同的环境，因此分列 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `Dataset` 自定义 , (实现在 `AsData.py` 中，需要在这里import）\n",
    "2. 全连接神经网络 `Net()` 类 (继承自 `nn.Module`)\n",
    "3. 网络训练和测试\n",
    "4. 使用 `argparse` 提供自定义参数设计并提供保存模型端口\n",
    "\n",
    "* 采用 `Dataset` 类 , 规范化的 epoch-batch 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using mps!\n",
      "Train Epoch: 1 [0/1554 (0%)]\t Total Loss: 4019.420898\n",
      "Train Epoch: 1 [160/1554 (10%)]\t Total Loss: 405.801178\n",
      "Train Epoch: 1 [320/1554 (20%)]\t Total Loss: 1021.465210\n",
      "Train Epoch: 1 [480/1554 (31%)]\t Total Loss: 1818.807373\n",
      "Train Epoch: 1 [640/1554 (41%)]\t Total Loss: 1557.671753\n",
      "Train Epoch: 1 [800/1554 (51%)]\t Total Loss: 504.166534\n",
      "Train Epoch: 1 [960/1554 (61%)]\t Total Loss: 864.955688\n",
      "Train Epoch: 1 [1120/1554 (71%)]\t Total Loss: 1038.923340\n",
      "Train Epoch: 1 [1280/1554 (82%)]\t Total Loss: 1475.345581\n",
      "Train Epoch: 1 [1440/1554 (92%)]\t Total Loss: 568.062134\n",
      "\n",
      "Test set: Average loss: 6.2459\n",
      "\n",
      "Train Epoch: 2 [0/1554 (0%)]\t Total Loss: 407.871307\n",
      "Train Epoch: 2 [160/1554 (10%)]\t Total Loss: 473.562439\n",
      "Train Epoch: 2 [320/1554 (20%)]\t Total Loss: 310.933075\n",
      "Train Epoch: 2 [480/1554 (31%)]\t Total Loss: 574.881592\n",
      "Train Epoch: 2 [640/1554 (41%)]\t Total Loss: 231.965652\n",
      "Train Epoch: 2 [800/1554 (51%)]\t Total Loss: 361.289124\n",
      "Train Epoch: 2 [960/1554 (61%)]\t Total Loss: 125.657951\n",
      "Train Epoch: 2 [1120/1554 (71%)]\t Total Loss: 470.898682\n",
      "Train Epoch: 2 [1280/1554 (82%)]\t Total Loss: 1702.533936\n",
      "Train Epoch: 2 [1440/1554 (92%)]\t Total Loss: 169.940826\n",
      "\n",
      "Test set: Average loss: 1.9873\n",
      "\n",
      "Train Epoch: 3 [0/1554 (0%)]\t Total Loss: 260.143127\n",
      "Train Epoch: 3 [160/1554 (10%)]\t Total Loss: 210.040909\n",
      "Train Epoch: 3 [320/1554 (20%)]\t Total Loss: 82.628456\n",
      "Train Epoch: 3 [480/1554 (31%)]\t Total Loss: 168.932953\n",
      "Train Epoch: 3 [640/1554 (41%)]\t Total Loss: 189.378586\n",
      "Train Epoch: 3 [800/1554 (51%)]\t Total Loss: 229.423004\n",
      "Train Epoch: 3 [960/1554 (61%)]\t Total Loss: 150.511902\n",
      "Train Epoch: 3 [1120/1554 (71%)]\t Total Loss: 171.218445\n",
      "Train Epoch: 3 [1280/1554 (82%)]\t Total Loss: 243.619659\n",
      "Train Epoch: 3 [1440/1554 (92%)]\t Total Loss: 161.969467\n",
      "\n",
      "Test set: Average loss: 0.2758\n",
      "\n",
      "Train Epoch: 4 [0/1554 (0%)]\t Total Loss: 122.141541\n",
      "Train Epoch: 4 [160/1554 (10%)]\t Total Loss: 172.458374\n",
      "Train Epoch: 4 [320/1554 (20%)]\t Total Loss: 117.791122\n",
      "Train Epoch: 4 [480/1554 (31%)]\t Total Loss: 93.196075\n",
      "Train Epoch: 4 [640/1554 (41%)]\t Total Loss: 108.702499\n",
      "Train Epoch: 4 [800/1554 (51%)]\t Total Loss: 106.187180\n",
      "Train Epoch: 4 [960/1554 (61%)]\t Total Loss: 120.730064\n",
      "Train Epoch: 4 [1120/1554 (71%)]\t Total Loss: 66.673553\n",
      "Train Epoch: 4 [1280/1554 (82%)]\t Total Loss: 133.850388\n",
      "Train Epoch: 4 [1440/1554 (92%)]\t Total Loss: 455.174805\n",
      "\n",
      "Test set: Average loss: 0.4070\n",
      "\n",
      "Train Epoch: 5 [0/1554 (0%)]\t Total Loss: 44.878891\n",
      "Train Epoch: 5 [160/1554 (10%)]\t Total Loss: 83.043083\n",
      "Train Epoch: 5 [320/1554 (20%)]\t Total Loss: 71.849556\n",
      "Train Epoch: 5 [480/1554 (31%)]\t Total Loss: 69.213470\n",
      "Train Epoch: 5 [640/1554 (41%)]\t Total Loss: 90.830917\n",
      "Train Epoch: 5 [800/1554 (51%)]\t Total Loss: 99.327179\n",
      "Train Epoch: 5 [960/1554 (61%)]\t Total Loss: 37.653786\n",
      "Train Epoch: 5 [1120/1554 (71%)]\t Total Loss: 40.519424\n",
      "Train Epoch: 5 [1280/1554 (82%)]\t Total Loss: 44.781780\n",
      "Train Epoch: 5 [1440/1554 (92%)]\t Total Loss: 44.954273\n",
      "\n",
      "Test set: Average loss: 0.1811\n",
      "\n",
      "Train Epoch: 6 [0/1554 (0%)]\t Total Loss: 67.698341\n",
      "Train Epoch: 6 [160/1554 (10%)]\t Total Loss: 15.223293\n",
      "Train Epoch: 6 [320/1554 (20%)]\t Total Loss: 29.717424\n",
      "Train Epoch: 6 [480/1554 (31%)]\t Total Loss: 36.680073\n",
      "Train Epoch: 6 [640/1554 (41%)]\t Total Loss: 51.852146\n",
      "Train Epoch: 6 [800/1554 (51%)]\t Total Loss: 46.966484\n",
      "Train Epoch: 6 [960/1554 (61%)]\t Total Loss: 35.865494\n",
      "Train Epoch: 6 [1120/1554 (71%)]\t Total Loss: 286.864319\n",
      "Train Epoch: 6 [1280/1554 (82%)]\t Total Loss: 60.655876\n",
      "Train Epoch: 6 [1440/1554 (92%)]\t Total Loss: 108.657593\n",
      "\n",
      "Test set: Average loss: 0.1611\n",
      "\n",
      "Train Epoch: 7 [0/1554 (0%)]\t Total Loss: 16.929771\n",
      "Train Epoch: 7 [160/1554 (10%)]\t Total Loss: 306.565125\n",
      "Train Epoch: 7 [320/1554 (20%)]\t Total Loss: 20.821838\n",
      "Train Epoch: 7 [480/1554 (31%)]\t Total Loss: 25.575911\n",
      "Train Epoch: 7 [640/1554 (41%)]\t Total Loss: 56.456635\n",
      "Train Epoch: 7 [800/1554 (51%)]\t Total Loss: 83.031738\n",
      "Train Epoch: 7 [960/1554 (61%)]\t Total Loss: 106.258369\n",
      "Train Epoch: 7 [1120/1554 (71%)]\t Total Loss: 12.981087\n",
      "Train Epoch: 7 [1280/1554 (82%)]\t Total Loss: 22.135847\n",
      "Train Epoch: 7 [1440/1554 (92%)]\t Total Loss: 38.911964\n",
      "\n",
      "Test set: Average loss: 0.1590\n",
      "\n",
      "Train Epoch: 8 [0/1554 (0%)]\t Total Loss: 76.896133\n",
      "Train Epoch: 8 [160/1554 (10%)]\t Total Loss: 17.656572\n",
      "Train Epoch: 8 [320/1554 (20%)]\t Total Loss: 49.158806\n",
      "Train Epoch: 8 [480/1554 (31%)]\t Total Loss: 17.546406\n",
      "Train Epoch: 8 [640/1554 (41%)]\t Total Loss: 33.331287\n",
      "Train Epoch: 8 [800/1554 (51%)]\t Total Loss: 103.513954\n",
      "Train Epoch: 8 [960/1554 (61%)]\t Total Loss: 39.007553\n",
      "Train Epoch: 8 [1120/1554 (71%)]\t Total Loss: 33.562321\n",
      "Train Epoch: 8 [1280/1554 (82%)]\t Total Loss: 36.681313\n",
      "Train Epoch: 8 [1440/1554 (92%)]\t Total Loss: 25.421383\n",
      "\n",
      "Test set: Average loss: 0.1829\n",
      "\n",
      "\n",
      "Expected loss: Average loss: 1.2000\n",
      "\n",
      "time_cost: 116.003005027771\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision import transforms\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "from AsData import AsData\n",
    "import pdb\n",
    "\n",
    "# 全局变量\n",
    "PATH = \"./2022期末数据/NMDS_coordinates.csv\"\n",
    "X_NAME = ['mean_rug', 'sd_rug', 'se_rug', 'DIST', 'X_dist',\n",
    "          'date_diff', 'days', 'Vel', 'X_Vel', 'MidPt']\n",
    "Y_NAME = ['NMDS1']\n",
    "\n",
    "output = {}\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# 网络结构\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):  \n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10, 50)\n",
    "        self.fc2 = nn.Linear(50,1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p =0.1, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        #print(x.shape)\n",
    "        return x\n",
    "\n",
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # print(data.shape,target.shape)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad() # clean the grad\n",
    "        output = model(data)\n",
    "        # print(output,output.shape)\n",
    "        #pdb.set_trace()\n",
    "        loss = F.mse_loss(output, target, reduction='sum')\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step() # update params\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\t Total Loss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            if args.dry_run:\n",
    "                break\n",
    "        train_loss += loss.item()\n",
    "    train_losses.append(train_loss / len(train_loader.dataset))  # epoch train loss\n",
    "    return\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval() # 设定dropout状态\n",
    "    test_loss = 0\n",
    "    with torch.no_grad(): # 不必在验证集上进行求导\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.mse_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "\n",
    "    test_loss /= len(test_loader.dataset) # 在测试集上按样本数取平均\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}\\n'.format(test_loss))  # epoch test loss\n",
    "    return test_loss\n",
    "\n",
    "def main():\n",
    "    # Training settings\n",
    "    parser = argparse.ArgumentParser(description='Example for Pytorch')\n",
    "    parser.add_argument('--batch-size', type=int, default=16, metavar='N',help='input batch size for training (default: 16)')\n",
    "    parser.add_argument('--test-batch-size', type=int, default=16, metavar='N',help='input batch size for testing (default: 16)')\n",
    "    parser.add_argument('--epochs', type=int, default=8, metavar='N',help='number of epochs to train (default: 8)')\n",
    "    parser.add_argument('--lr', type=float, default= 0.5, metavar='LR',help='learning rate (default: 0.5)')\n",
    "    parser.add_argument('--gamma', type=float, default=0.7, metavar='M',help='Learning rate step gamma (default: 0.7)')\n",
    "    parser.add_argument('--no-cuda', action='store_true', default=False,help='disables CUDA training')\n",
    "    parser.add_argument('--dry-run', action='store_true', default=False,help='quickly check a single pass')\n",
    "    parser.add_argument('--seed', type=int, default=1, metavar='S',help='random seed (default: 1)')\n",
    "    parser.add_argument('--log-interval', type=int, default=10, metavar='N',help='how many batches to wait before logging training status')\n",
    "    parser.add_argument('--save-model', action='store_true', default=False,help='For Saving the current Model')\n",
    "    args,unkown = parser.parse_known_args()\n",
    "    use_cuda = torch.backends.mps.is_available()\n",
    "\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    device = torch.device(\"mps\" if use_cuda else \"cpu\")\n",
    "    print(f\"You are using {device}!\")\n",
    "    #device = torch.device(\"cpu\")\n",
    "\n",
    "    train_kwargs = {'batch_size': args.batch_size}\n",
    "    test_kwargs = {'batch_size': args.test_batch_size}\n",
    "    if use_cuda:\n",
    "        cuda_kwargs = {'num_workers': 1,\n",
    "                       'pin_memory': True,\n",
    "                       'shuffle': True}\n",
    "        train_kwargs.update(cuda_kwargs)\n",
    "        test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "    \n",
    "    file = pd.read_csv(PATH)\n",
    "    file = file[['NMDS1','mean_rug', 'sd_rug', 'se_rug', 'DIST', 'X_dist',\n",
    "                'date_diff', 'days', 'Vel', 'X_Vel', 'MidPt']]\n",
    "\n",
    "    r = int(file.shape[0]*0.8)\n",
    "\n",
    "    index = np.random.permutation(file[X_NAME].shape[0]) # 利用index随机打乱数据\n",
    "    index1 = index[:r]\n",
    "    index2 = index[r:]\n",
    "    X_train = np.array(file[X_NAME].iloc[index1])\n",
    "    y_train = np.array(file[Y_NAME].iloc[index1]).ravel()\n",
    "    X_test = np.array(file[X_NAME].iloc[index2])\n",
    "    y_test = np.array(file[Y_NAME].iloc[index2]).ravel()\n",
    "    del file # 释放内存\n",
    "\n",
    "    transformation = transforms.Compose([transforms.GaussianBlur(5)])\n",
    "\n",
    "    train_dataset = AsData(X_train,y_train,False)\n",
    "    test_dataset = AsData(X_test,y_test,False)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,**train_kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, **test_kwargs)\n",
    "    \n",
    "    model = Net().to(device)\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=args.lr) # 注册优化器 Adadelta\n",
    "    scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
    "    \n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "        val_epoch_loss = test(model, device, test_loader)\n",
    "        scheduler.step()\n",
    "        val_losses.append(val_epoch_loss) # epoch test loss\n",
    "    print('\\nExpected loss: Average loss: {:.4f}\\n'.format(np.mean(val_losses)))    \n",
    "\n",
    "    if args.save_model:\n",
    "        torch.save(model.state_dict(), \"model.pt\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    warnings.filterwarnings('ignore')\n",
    "    t0 = time.time()\n",
    "    main()\n",
    "    t1 = time.time()\n",
    "    print('time_cost:', t1 - t0)\n",
    "\n",
    "    # 输出损失图像\n",
    "    plt.plot(range(1,len(train_losses)+1),train_losses,'bo',label = 'training loss')\n",
    "    plt.plot(range(1,len(val_losses)+1),val_losses,'r',label = 'validation loss')\n",
    "    plt.legend()\n",
    "    plt.savefig ( \"./output/Path.svg\", dpi= 300, format = \"svg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64712b4c5a09ad27f83a3a6083a24769aa5f924da2ebbca777af02868704b9da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
